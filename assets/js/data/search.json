[ { "title": "Java util.concurrent package", "url": "/posts/java-concurrent-package/", "categories": "java", "tags": "", "date": "2022-12-03 23:00:00 +0800", "snippet": "JAVA concurrentjava.util.concurrent is package that provides classes/interfaces that related to concurrent executionImportant interfaces/classesRespresent the object that can execute the given task(either current therad or another thread) Executor : Object that can run a given task(Runnable). ExecutorService : More useful method than Executor. It provides methods to summit task, then give back Future. ScheduledExecutorService : Can execute task given delay in future or execute periodically. ForkJoinPool : An ExecutorService that implement work-stealing algorithms. Thread in the pool can steal work which in the pending queue of another thread. Executors : The class that contains factory methods use for create Thread pool.Wrapper of task execution result Future : The wrapper of execution result that may success or fail. CompletableFuture : Provide more extensive usecase than Future(for example Composition)```java// Create executorService with single thread using factory method from Executorsvar executorService = Executors.newSingleThreadExecutor();Callable task = () -&amp;gt; { System.out.println(&quot;Perform something and return value&quot;); return 2;};// summit task to executorServiceFuture future = executorService.submit(task);try { // blocking the current thead until result is done var result = future.get(); System.out.println(“the result of computation is “ + result);} catch (InterruptedException | ExecutionException e) { System.out.println(“Exception!!! “ + e);}```Syscronizations CountDownLatch : Block with await method until count reach zero. Phaser : Extended functionality version of CountDownLatch. CyclicBarrier : Extended functionality version of CountDownLatch.Memory Synchronization Lock : More extensive locking mechanism that synchronized keyword Semaphore : Respresent the resource counting that can be acquired and released." }, { "title": "Pandas 101", "url": "/posts/pandas-basic/", "categories": "datascience", "tags": "", "date": "2022-11-28 23:00:00 +0800", "snippet": "What Pandas isPandas is python library for data analysis. Its name came from “panel data”. We can import data from various source into datastructure so called “DataFrame” and do computation/manipulation operations on them as we wish.The basics DataFrame is the core class which consists Series(similiar to column) Series is column of DataFrameRead/Access operaionsUseful method to display informationdf.head() # display first n rows (default 5)df.tail() # display last n rows (default 5)df.info() # display concise summary sucj as columns name, data type, memory usagedf.columns # this is not method# display all columns labelRead methodsData access mental model is similar to how we access data on DB table. We can select row(s) or column(s), also apply filter condition.The data example | first | last | email ||—–|——-|——-|| Klur | Vinci | kl@gmail.com || Dao | Vinci | dao@email.com || John | Cater | jc@email.com || Java | Scala | js@email.com |# select a columndf[&#39;first&#39;] # or df.first# select columnsdf[[&#39;first&#39;, &#39;last&#39;]]# select a rowindex = 0 df.loc[index] # or df.iloc[index] # select rowsdf.loc[[0,1]] # or df.iloc[[0,1]]# select portion of DataFrame# df.loc[row(s), col(s)]df.loc[0, [&#39;first&#39;, &#39;last&#39;]] # ordf.iloc[0, [0, 1]]df.loc[[0,1], [&#39;first&#39;, &#39;email&#39;]] # ordf.iloc[[0,1], [0,2]]# or with slice operator to do range selectdf.loc[0:2, &#39;first&#39;:&#39;email&#39;] loc vs iloc methodBoth method usage are the same, are used to access portion of Dataframe by row(s) or column(s). The difference is the parameters. loc accessor parameters are label(s) whereas iloc accessor parameters are index based.Filtering rowWe can pass Series of boolean to select rows as we want. To create boolean Series, we do as the followingfilter = df[&#39;last&#39;] == &#39;Vinci&#39;df[filter] # select all columndf.loc[filter, [&#39;first&#39;, &#39;last&#39;]] # select only 2 columnsUpdate# Update a single celldf.at[0, &#39;first&#39;] = &#39;Klur2&#39; # ordf.loc[0, &#39;first&#39;] = &#39;Klur2&#39;## Update schema## Add/Drop columndf[&#39;middle&#39;] = &quot;init middle&quot;df.drop(columns=[&#39;middle&#39;], inplace=True)The official cheat sheet from Pandashttps://pandas.pydata.org/Pandas_Cheat_Sheet.pdf" }, { "title": "Scala 101", "url": "/posts/scala-basic/", "categories": "scala", "tags": "", "date": "2022-11-20 23:00:00 +0800", "snippet": "Scala Scala is a language that base on JVM Scala is functional language that inherit from Haskell Functions are first class citicen in Scalaval, var, def, lazy val val : val is immutable data type, evaluates only once var : var is mutable def : is method, evaluates every time it gets called lazy val : similar to val, but the value is evaluates once when the first access is called val immutable = 1 // similar to final in Javaval func1 = (a: Int, b: Int) =&amp;gt; a+b // this is functionvar mutable = &quot;this can be changed&quot;def method1 = (a: Int, b: Int) =&amp;gt; a+b //methodlazy val lazyVal = { println(&quot;init lazily&quot;) 3} Block{} is combinded expressions the result of the last expression is the returned the block{ println(&quot;init val&quot;) 5 // this is the return val P}Object classObject class is signlenton/static which there is only 1 instance on JVM.Companion objectCompanion object is an object with the same name as class in the same file. It’s used for store instance-indepedent field/method (static) related to the class. For example, we can put factory related method into Companion object.Case classCase class is class that Scala help implement a lot of methods automatically(similar to record in Java) All parameters are val and public hashCode, equal, apply, unapply and so on```scalacase class Person(name: String, age: Int)val klur = Person(“klur”, 28) // don’t need new because apply is automatically implemented# Pattern matchingPattern matching is the powerful feature that extends from simple switch case```scalaval matcherFunc = (a: Int) =&amp;gt; a match { case 1 =&amp;gt; 1 case 5 =&amp;gt; &quot;is five&quot; case _ =&amp;gt; &quot;the rest&quot;}//Pattern matching also work with case classval klurSay = klur match { case Employee(name) =&amp;gt; s&quot;$name is just normal guy&quot; case Boss(name, age) if age &amp;gt; 40 =&amp;gt; s&quot;$name is a old $age boss&quot; case Boss(name, age) if age &amp;lt;= 40 =&amp;gt; s&quot;$name is a young $age boss&quot; }Pattern guardsPattern guards is a way to seperate the pattern matching by using if condition like the example aboveExtension methods and Implicit classesExtension methods is the way to add method to an existing type or 3-party type which added in Scala3 which previously we can achive it by using Implicit classesobject StringExtensions { extension (str: String) { def toSnakeCase = { str.replaceAll(&quot;([A-Z])&quot;, &quot;_&quot; + &quot;$1&quot;).toLowerCase } } }Try, OptionThey are classes that wrap that actual underlining data. They are case class, so we can handle them using case matching. Another example is Future.onComplete() which take Try[T] =&amp;gt; U as arguments.Try -&amp;gt; Success or ExceptionOption -&amp;gt; Some or Noneval possibleException = Try(throw new RuntimeException(&quot;PANIC&quot;))val result = possibleException match { case Success(_) =&amp;gt; &quot;it success somehow&quot; case Failure(exception) =&amp;gt; s&quot;error with ${exception.getMessage}&quot;}println(result)For comprehensionsThe form of it is for (enumerators) yield e. They looks are equivalent to collection that concatinated using flatMap that produce as e in List.val looping = for { x &amp;lt;- List(1,2) y &amp;lt;- List(3,4)} yield (x,y)looping.foreach((a: Int, b: Int) =&amp;gt; println(s&quot;$a and $b&quot;))//1 and 3//1 and 4//2 and 3//2 and 4CurryingCurring is the process of converting a fucntion with multiple arguments into funtion with less argument(less generic).def applyTo(operation: (Int, Int) =&amp;gt; Int)(a: Int, b: Int): Int = { operation(a,b)}val plusOperation = (arg1: Int, arg2: Int) =&amp;gt; arg1 + arg2val plus: (Int, Int) =&amp;gt; Int = applyTo(plusOperation)println(plus(1,2)) // =3val exponentialOperation = (arg1: Int, arg2: Int) =&amp;gt; Math.pow(arg1,arg2).toIntval exponential: (Int, Int) =&amp;gt; Int = applyTo(exponentialOperation)println(exponential(2,3)) // =8" }, { "title": "Scala Generic", "url": "/posts/scala-generic/", "categories": "scala", "tags": "", "date": "2022-11-13 23:00:00 +0800", "snippet": "Scala GenericScala type system support generic. Generic classes are classes that take a type(s) as parameter. For example, List[T], Seq[T], Option[T].The following code will be used as an example for the rest of this article.trait Animalabstract class Mammal extends Animal { def name(): String}case class Dog(name: String) extends Mammalcase class Cat(name: String) extends Mammalabstract class Fishcase class Salmon() extends Fishcase class Mackerel() extends Fish// Animal// | |// Mammal Fish// | | | |// Dog Cat Salmon MackerelUpper bound and lower boundUpper bound / Lower bound is the way to restrict that possible type that can be received.Systax[T &amp;lt;: UpperBoundType] [T &amp;gt;: LowerBoundType][T &amp;lt;: UpperBoundType &amp;gt;: LowerBoundType] Upper bound : The way to limited type parameter. Let say, we want to write a method that take wrapper of mammal```scalaval dog = Dog(“Tu”)val cat = Catog(“Pom”)// the below method will cause complie error because it doesn’t understand name() method that it exists. Therefore, we need to tell complier that T in this method will only Mammal or class below it.def mammalSpeakT: Unit = { println(mammal.name())}// to fix it, we need to add Upperbound =&amp;gt; &amp;lt;: Mammaldef mammalSpeakT &amp;lt;: Mammal: Unit = { println(mammal.name())}- Lower bound : Normally, we should not use lowerbound, except we develop library. Anyway, the logic is similar to upperbound but opposite instead. The type of lower bound is restrict that only accept the classes that are ancestor of the bounded type.```scaladef classThatAreSuperOfDog[T &amp;gt;: Dog](wrapper: Wrapper[T]): Unit = { println(wrapper.toString)}CovariantCovariant is the concept that describe the relation of Generic classes regarding the type parameter. The reason that this exists is because that complier cannot assume the relation of Wrapper classes(List, Seq, Option, and so on). List[Dog] is not consider to be subtype of List[Animal] unless we specify that it is.There are 3 type of relationship Covariance : This means the relation of Wrapper class is aligned the same way of its generic type Contravariance : This means the relation of Wrapper class is aligned the opposite way of its generic type Invariance : This is the default one which means there isn’t relation at all.Usecase 1case class Wrapper[T](data: T) { def underlining(): T = data}val w1: Wrapper[Dog] = Wrapper(Dog(&quot;asd&quot;))val w2: Wrapper[Animal] = w1 //this cause complie error because Wrapper[Dog] isn&#39;t subtype of Wrapper[Animal]. We have to tell complier explicitly by add `Covariance` `+` sign to generic typecase class Wrapper[+T](data: T) { def underlining(): T = data}//TODOUsecase 2" }, { "title": "Big O", "url": "/posts/big-o/", "categories": "misc", "tags": "", "date": "2022-03-10 23:00:00 +0800", "snippet": "Analysis of AlgorithmsThe naive way to compare the performanace of 2 algorithms is to run both of them by given the same input and measure time or space that they use. This is quite not effective some algorithms might good at small dataset but get worse at large or vise versa. To measure performance of algorithms, we use Asymptotic analysis to do. It’s mathematical analysis on algorithms f(n) as n(number of input) -&amp;gt; ∞. Which we also usually expressed as Big O notation.All Bigs Big OAlso calls upper bound, the worst case. Big Omega ΩAlso calls lower bound, the best case. Big Theta ΘSome algorithms have difference performanace given same input size but difference input data. For example, find String in sorted string list. Let’s say the algorithm is simple brute force looping. The lower bound(best case) is that the answer is at the first of the list, so Big Omega is Ω(1). In contrast, if the answer is at the last of the list, then this is consider the worst case because we have to check one by one until the end, so Big O is O(n)." }, { "title": "Java IO package", "url": "/posts/java-io-package/", "categories": "java", "tags": "", "date": "2022-02-16 23:00:00 +0800", "snippet": "JAVA IOjava.io is package that provides system input and output through data streams. Read write file, socket.Important interface/abstractClosable: to indicate that this class hold resource that needed to be closed. For example, opens file void close()AutoCloseable : same as Closable but method close will be invoked if object is declared in try-with-resources header block void close()graph LR; Closable--&amp;gt;|extends|AutoCloseable;InputStream : abstract class that representing an input stream of bytegraph RL; ByteArrayInputStream--&amp;gt;|extends|InputStream; BufferedInputStream--&amp;gt;|extends|InputStream; etc[... and much more]--&amp;gt;|extends|InputStream;OutputStream : abstract class that representing an output stream of bytegraph RL; ByteArrayOutputStream--&amp;gt;|extends|OutputStream; BufferedOutputStream--&amp;gt;|extends|OutputStream; etc[... and much more]--&amp;gt;|extends|OutputStream;Example implementation BufferedInputStream : buffered bytes in to array that support make and reset so that user can repeatly read some bytes BufferedOutputStream : buffered bytes in to array before flush bytes to underling OutputStream, to achive a better performace by avoid costly actionReader: abstract class for reading character streamsWriter: abstract class for writing character streamsgraph RL; BufferedReader--&amp;gt;|extends|Reader; FileReader--&amp;gt;|extends|Reader; etc[... and much more]--&amp;gt;|extends|Reader;graph RL; ByteArrayOutputStream--&amp;gt;|extends|OutputStream; BufferedOutputStream--&amp;gt;|extends|OutputStream; etc[... and much more]--&amp;gt;|extends|OutputStream;Example usage of Java IO with simple echo serverServer side code@Slf4jclass EchoServer { @SneakyThrows public static void main(String[] args) { final int port = 8080; //Create a Server socket and bound to specify port for TCP connection. final var ss = new ServerSocket(port); log.info(&quot;Start server at port : &quot; + port); while (true) { //Put socket.accept and in/out stream in try() to execute autoClosable after all communication try ( //ss.accept is block until connection is created. var socket = ss.accept(); //Create BufferedReader so that we can use readLine(), It need &#39;Reader&#39; in constructure which can created from &#39;InputStream&#39; of socket var inReader = new BufferedReader(new InputStreamReader(socket.getInputStream())); // PrintWriter so that we can print String into it. var outWriter = new PrintWriter(socket.getOutputStream(), true) ) { log.info(&quot;Get connection from : &quot; + socket.getLocalAddress() + &#39;:&#39; + socket.getPort()); String inputLine; //Get next line until it&#39;s null while ((inputLine = inReader.readLine()) != null ) { log.info(&quot;Server received : &quot; + inputLine); outWriter.println(inputLine + &quot; is echo&quot;); } } } }}Socket provide InputStream for incoming data and OutputStearm for outgoing data. With BufferedReader, we can read as String line by line. Similar to PrintWriter to warp so that we can print line into underlining stream.Client side command# this will open TCP socket in interactive mode. we can send message with enter.nc localhost 8080..." }, { "title": "Data Structure", "url": "/posts/data-structure/", "categories": "misc", "tags": "", "date": "2022-02-09 22:00:00 +0800", "snippet": "Linear Data structureArrayFix size data structure.[A][B][C][D]Linked list Linear data structure similar to Array. Instead of allocates data size by size, let each node contains data and a reference to next node. With these, insertion and deletion cost are reduced significantly. Singly Linked List : each node have only a reference to next one. Doubly Linked List : each node have only a reference to next one and also previous one. Circular Linked List : each node points to the next one in circular.[A]-&amp;gt;[B]-&amp;gt;[C]-&amp;gt;[D]Stack LIFO : Last in, first out. Can implemented by using both array and linked list.Push A----------------[A]----------------Push B----------------[B][A]----------------Push C----------------[C][B][A]----------------Pop | return C----------------[B][A]----------------Pop | return B----------------[A]----------------Queue FIFO : First in, first out Can implemented by using both array and linked list.Enqueue A----------------[A]----------------Enqueue B----------------[B][A]----------------Enqueue C----------------[C][B][A]----------------Dequeue | return A----------------[C][B]----------------Dequeue | return B----------------[C]----------------Non-linear Data structureTree Unlike all above, trees are hierarchical data structures. Each node of tree can have 0..n of children. The 2 ways to traverses through tree Depth First Traversal : Go throught the left/right most until end of depth A -&amp;gt; B -&amp;gt; E -&amp;gt; F -&amp;gt; G -&amp;gt; C -&amp;gt; D -&amp;gt; H Breadth First Traversal : Go throught tree by layer of depth A -&amp;gt; B -&amp;gt; C -&amp;gt; D -&amp;gt; E -&amp;gt; F -&amp;gt; G -&amp;gt; H graph TB; A--&amp;gt;B; B--&amp;gt;E; B--&amp;gt;F; B--&amp;gt;G; A--&amp;gt;C; A--&amp;gt;D; D--&amp;gt;H;Binary Tree Node in binary tree have at most 2 children(0..2).graph TB; A--&amp;gt;B; B--&amp;gt;E; B--&amp;gt;F; A--&amp;gt;C; A--&amp;gt;D; D--&amp;gt;H;Binary Search Tree(BST) The left node have key value less than parent’s key The right node have key value less than parent’s key 2 rules above are apply though BST Because of how data is ordered. Operations(search, insertion, deletion) are depends on its height. Since at each level 2 times of data can be stored, height = log(n).graph TB; 20--&amp;gt;10; 10--&amp;gt;2; 10--&amp;gt;12; 20--&amp;gt;35; 35--&amp;gt;30; 35--&amp;gt;37; 30--&amp;gt;29;Heap It’s a complete tree. All level are filled until full from left most. It’s used for implementation of priority queue. Min Heap : The root(top node) has minimum key value. All sub tree also have this property recursively.graph TB; 1--&amp;gt;2; subgraph sub tree 2--&amp;gt;17; 17--&amp;gt;25; 2--&amp;gt;19; end 1--&amp;gt;3; 3--&amp;gt;40; 3--&amp;gt;9; Max Heap : The root(top node) has maximum key value. All sub tree also have this property recursively.graph TB; 100--&amp;gt;19; 19--&amp;gt;17; 19--&amp;gt;3; 100--&amp;gt;35; subgraph sub tree 35--&amp;gt;25; 35--&amp;gt;1; endHash Hash is function that can take arbitrary lenght of input and return fix lenght output Good hash function have uniformly distributed key which means if input changes just a bit output will change completely It can be used as cached/ database indexing" }, { "title": "Java Reactive", "url": "/posts/java-reactive/", "categories": "java", "tags": "", "date": "2022-01-24 23:00:00 +0800", "snippet": "Reactive Streams Provides standard for asynchronous stream, non-blocking applications. Use “Pull” model (Subscriber ask for data) instead of “Push” model (Publisher publish data)There are 4 interfacesPublisher&amp;lt;T&amp;gt; -&amp;gt; provides bounb/unbound elements that publishing according to Sucscriber(s) void subscribe(Subscriber&amp;lt;? super T&amp;gt; s); : calls to subscribe to publisher, each call will start new Subscription.Processor&amp;lt;T, R&amp;gt; -&amp;gt; be both Publisher and SucscriberSubscriber&amp;lt;T&amp;gt; -&amp;gt; void onSubscribe(Subscription s); : invoke after calling Publisher.subscribe void onNext(T t); : data sent by Publisher as request(one at a time) void onError(Throwable t); to notifies errors and no more elements will be published void onComplete(); : to notifies all data sents and no more elements will be publishedSubscription -&amp;gt; void request(long n); : request n elements from Publisher void cancel(); : inform Publisher to stop publishing data to this SubscriptionJava 9 Flow interfacesLater, Java team includes Reactive Streams specification in to JDK, so calls Java 9 Flow interfaceImplementation of Reactive Streams RxJava Reactor Akka streamRxJava RxAndroid is an extension to RxJava Observable = Publisher imeplementation that emits 0..n elements There are also others types Flowable, Single, Maybe Disposable is subscription that we can use for cancellationReactor Spring webflux is base of Reactor Cold stream = static, fix lenght stream of data. For example, harcoded Flux.just(…). Hot stream = dynamic, infinite stream of data. For example, data from Kafka. Mono = Publisher imeplementation that emits 0..1 elements Flux = Publisher imeplementation that emits 0..n elements" }, { "title": "Protocals(Sort of) that backends should know", "url": "/posts/protocals/", "categories": "misc", "tags": "", "date": "2021-12-15 23:00:00 +0800", "snippet": "RESTful APIs (Just a HTTP) It’s actually “software architectural style” that introduce by Roy Fielding not a protocal Simple CRUD API that build on top of HTTP protocal that try to match CRUD operation with HTTP verb Since it’s build on top of HTTP, so it only supports request-response communication Data format usually be JSON, but sometimes XML(rarely) OpenAPI is the specifiation defind RESTful APIs, Swagger is a tool for imeplementing OpenAPI RESTful APIs isn’t defined how to do authentiation and authorization. Pros : Simeple, Lot of example, Mature Cons : Let see later… Usecases : Normal CURD operation Server to server compunication Websocket It’s protocal at OSI layer 7 works over TCP It’s stateful constrat to HTTP which is stateless Full duplex communication No Header support. Need sub protocal for real application useage STOMP messaging protocal is commonly use on top of Websocket for actual usage Pros : Can send realtime message initiated from server Cons : Since it’s stateful, It’s hard to scale horizontally Usecases : Realtime chat Server push update notification GraphQL It’s application protoacal built on top of HTTP/2 Client able to conastruct query to get desired data response Pros : Client can just ask for what it needs, Reduce network useages Cons : Sever need to implement additional logic to support GraphQL, Steep learning curve compare to Simple RESTful Usecases : Realtime chat Server push update notification gRPC It’s application protoacal built on top of HTTP/2 Protobuf(Protocol Buffers) is used for de/serialization which is binanry format Client can call server method with arguments same as native function More efficient It doesn’t work with web broswer Pros : Very efficient, Don’t need to worry about HTTP stuff(eg verb) Cons : Lack of community, Harder to debug compare to plain HTTP, Steep learning curve compare to plain HTTP Usecases : Same as RESTful APIs but for server to server only Rsocket It’s protocal at layer 5 and 6 It supports many type of communication model, Request/response, Request/stream, Fire-and-forget and Channel Fully implement Reactive stream Pros : Very efficient, Built-in flow control(eg back pressure) Cons : Lack of community, Steep learning curve compare to HTTP Usecases : Same as RESTful APIs but for server to server only " }, { "title": "OAuth, OpenID Connect and SAML", "url": "/posts/oauth-openId-saml/", "categories": "misc", "tags": "", "date": "2021-09-29 23:00:00 +0800", "snippet": "Background Authenticaion : is the process that to confirm that users are who they claim they are. Think of computer user/password that allow the users who knows user/password to get in. Authorization : is about the security to allow/permit users to do action they want to. Think of users right on computer, normal users can’t access admin’s filesOAuthOAuth stands afor Open Authorization. It is commonly used way of grants 3rd party application to access user resources on another server. OAuth is focus on authorization not authenticaion. Latest OAuth specification is 2.1 as of now The OAuth specification is written base on on HTTP protocal It’s token based authorization (JWT) OAuth specify flows/grants(interaction between roles). Flow is depend on application type( SPA, mobile, so on)RolesOAuth defines 4 roles. Resource owner(RO) : A person or entity that have capable of granting access to a protected resource. Resource server(RS) : The server that hosting the protected resources. Client : An application that makeing request to access the protected resources on bahalf of resource owner. Sometimes called 3rd party application. Authorization server(AS) : The server that capable of issue an access token to client.OpenIDOpenID Connect is built on top of OAuth. Since OAuth just focus on authorization and leave authenticaion out of scope. OpenID Connect is created to cover authenticaion by extending OAuth protocal.SAMLSAML stands for Security Assertion Markup Language. SAML is protocal that help provides authentication. SAML is older and more mature that OpenID.OpenID vs SAML Type OpenID SAML Maturity less more Protocal based on JWT(On top of OAuth) XML Purpose authentication authentication " }, { "title": "Network tools101", "url": "/posts/network-tools/", "categories": "network", "tags": "network", "date": "2021-09-20 20:00:00 +0800", "snippet": "TCP/IP Model Layer Example Application layer HTTP, SMTP, SSH Transport layer TCP, UCP Internet layer IP, ICMP Network access layer Ethernet pingThe most basic command used for determine if able to reach destination and also latency. It bases on ICMP protocal. Ping able be disabled if destination disable ICMP protocal.telnetUse for check the destination port Telnet able to used for identiy if destination port is opened.ipconfig/ifconfigTo get current network IP and the IP of gateway that we’re connectingWireless LAN adapter Wi-Fi: Connection-specific DNS Suffix . : Link-local IPv6 Address . . . . . : fe80::94c:63fe:66c8:2416%12 IPv4 Address. . . . . . . . . . . : 194.168.182.210 Subnet Mask . . . . . . . . . . . : 255.255.255.0 Default Gateway . . . . . . . . . : 194.168.182.1 IPv4 Address : the current IP that get assigned by router Default Gateway : IP of routerroute tableRoute table is the set of rules that used for determind the destination of data package on IP addresscommand : netstat -rnKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface0.0.0.0 10.244.1.1 0.0.0.0 UG 0 0 0 eth010.244.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0ngrokngrok helps create reverse proxy and point to local pc and also give public IP temporary. Local development with webhook API(Line bot, Zoom chat)Advance network tools Zenmap (nmap GUI) Wireshark" }, { "title": "Go fucntion101", "url": "/posts/go-function/", "categories": "programming-language", "tags": "go", "date": "2021-09-15 22:00:00 +0800", "snippet": "*Remark, I use term function for method in Java for simplicity.Go function syntaxI’ve experience in Java and try to learn Go. Then first thing that makes me confuse in go is function syntax structure.Arguments Java : type then parameter name (int a) GO : parameter name then parameter (a int)Return value Java : return value is placed in front of function name. Java only allows 1 only return value Go : return values is placed after function’s arguments. Go allows to return multiple valuesException Java : multiple throw exceptions is declare after function arguments Go : in Go they call error instead and it can return as part of return valuesJava examplepublic float divideBy(int a, int b) throws Exception { if (b == 0) { throw new IllegalArgumentException(&quot;divider should not be 0&quot;); } return (float) a / (float) b;}Go examplefunc divideBy(a, b int) (float32, error) { if b == 0 { return 0, errors.New(&quot;divider should not be 0&quot;) } return float32(a) / float32(b), nil}Go pass value/pointer and value/pointer receiver In Go, They data always pass by value (copy into function). Object that pass in function will be copied into function, so changes in function will not effect object in the caller scope. in Java, method isn’t first class citizen(It cannot exists without class). In contrast, function is first class citizen. Method in Java is attached to object since it’s always under class. Go can achieve the same thing using Receiverpackage mainimport ( &quot;fmt&quot;)type person struct { name string age int}func main() { person1 := &amp;amp;person{name: &quot;klur&quot;, age: 27} fmt.Println(&quot;before all : &quot;, person1) addAgeFunc(*person1, 10) // -- (1) fmt.Println(&quot;after added uning function&quot;, person1) addAgeFuncPnt(person1, 10) // -- (2) fmt.Println(&quot;after added uning function with pointer&quot;, person1) person1.addAgeReceiver(10) // -- (3) fmt.Println(&quot;after added uning function with receiver&quot;, person1) person1.addAgePntReceiver(10) // -- (4) fmt.Println(&quot;after added uning function with pointer receiver&quot;, person1)}//(1)func addAgeFunc(p person, i int) { p.age += i}//(2)func addAgeFuncPnt(p *person, i int) { p.age += i}//(3)func (p person) addAgeReceiver(i int) { p.age += i}//(4)func (p *person) addAgePntReceiver(i int) { p.age += i}(1) – Pass copy of value into functionThis way the person object inside function is another obecjt than original one, so that chaging values inside function won’t affect the original object as line 18 shown(2) – Pass pointer of object into functionThis way function get the pointer that references the original object, so that changing values inside function will effect that original object as line 20 showm(3) – Function with value receiverThis way function is attached to object, so we can call from object following by dot. Moreover, the person value is stil just a copy of original object. So changes still not affect the original(4) – Function with pointer receiverBeside able to call from object following by dot. This pass as pointe, so changing values will affect the original. This is equivalent to Java’s method." }, { "title": "Deployment strategy", "url": "/posts/deployment-strategy/", "categories": "devops", "tags": "devops", "date": "2021-09-09 22:00:00 +0800", "snippet": "RollingReplace the running instance with the new one. technical difficulty : low pros : easy to setup cons : able to test only after deploy finish which might effect usersBlue/GreenCreate whole new environment and tests it. After test successfully, then change routing. technical difficulty : medium pros : able to test pre-production before release to real users cons : have to provision entire environment when deploy to productionCanaryProvision both version in production but only route a few user to new feature to test if it’s good. This required kind of smart routing to be part of deployment strategy. technical difficulty : high pros : get real feedback from users before make decision to totally move to new version cons : need additional infrastructure setup and process to route and get feedback from new version" }, { "title": "Argocd101", "url": "/posts/argocd/", "categories": "devops", "tags": "devops", "date": "2021-09-09 22:00:00 +0800", "snippet": "ArgocdArgo CD is a declarative, GitOps continuous delivery tool for Kubernetes. It offers both command line interface and GUI.When to use Argocd We can deploy any application to K8s using just Kubectl but this way is error prone and tedious. To solve that, we can use Pipeline to help automate deployment process but with Argocd we can sync Git with actual infra in much better way. In case that we want to track infra application that we deploy in K8s. For example, our cluster needs Redis, Elasticsearch and RabbitMQ. we can deploy them using Argocd and helm to cluster.Alternative Flux" }, { "title": "Terraform101", "url": "/posts/terraform/", "categories": "devops", "tags": "devops, terraform", "date": "2021-09-08 16:00:00 +0800", "snippet": "TerraformTerraform is Infrastruture as Code(IaC) tool that provoides ablity to manage using declarative configuration files(.tf). It helps manage and contol infrastruture configuration.TerminologyPlan : “terraform plan” will check actual against configuration file and produce changes that will apply laterApply : “terraform apply” will do actual provisioning as proposed in planningResources BlockResource is the most basic and important block. This respresent resource on cloud server and its properties.exampleresource &quot;aws_instance&quot; &quot;web&quot; { ami = &quot;ami-005e54dee72cc1d00&quot; instance_type = &quot;t2.micro&quot;}ProvidersProviders are plugin that helps Terraform interact with cloud providers. Available providers is shown in Terraform RegistryInputs and Outputs Input variables : like function arguments.```variable “instance_type” {description = “type of EC2 instance to provision.”default = “t2.micro”}to use in resource block-&amp;gt; instance_type = ${var.instance_type}- Output variables : like return values. They is used for further required resource. For example, create virsual network and return ID to use for provision VM later on.output “public_dns { value = “${aws_instance.web.public_dns}”}### Terraform BackendSettings regard Terraform itself lies in here. The most important one is backend setting. For learning and tutorial, we can use local to store the state file. For production use, it&#39;s recommended to store in remote backend instead such as S3(AWS), Storage account(Azure).terraform { …}```Standard Module Structure main.tf : declear resource block variables.tf : declear variable to pass to main file outputs.tf : define the output of this module to let another module use later on or just to logAlternativeAWS CloudFormation" }, { "title": "Elasticstack101", "url": "/posts/elasticstack/", "categories": "devops", "tags": "devops", "date": "2021-09-08 15:00:00 +0800", "snippet": "ElasticStackElastic Stack is group of open source projects that previously called ELK stack. The stack helps users to get Data from various sources in any form, gather then store and finally visualize information.There are 4 major compoments of stack.BeatBeat is component that used for gather logs or metric installed as agent in server. Beat type depends on what kind of component that it attached. For application, the preferred way is to deploy as side-car. Beat types example are Filebeat, Metricbeat. User can define how input, processor, output works.Input -&amp;gt; Processor -&amp;gt; OutputExample --------- ------------------ ------------------| logfile | -&amp;gt; | - add metadata | -&amp;gt; | push to logstash || | | - encode to json | | | --------- ------------------ ------------------LogstashLogstash is data processing pipeline that support various format of input and help transform into common format that easy to be digested by downstream(in most cases Elasticsearch). Logstash can be customized by adding filters.ElasticSearchElasticSearch is text search and analytics engine that provide REST api interface for developer to interact with. In elasticstack, It serves as the main component that stores and computes data.KibanaThis is the last part of pipeline. Kibana provides web based GUI to user to visualize data that store in elasticsearch.Alternative Datadog Dynatrace" }, { "title": "Helm101", "url": "/posts/helm/", "categories": "devops", "tags": "devops, helm", "date": "2021-09-08 12:00:00 +0800", "snippet": "HelmHelm is package manager for K8s application. It can be compare with YUM and APT in Linux or Homebrew for Mac. We can install K8s application by add repository and then install. If we want to package own application the deploy in K8s which might have complex K8s component setup. Helm can help us by organized it using template.Why we need HelmWhen we deploy appliaction in K8s, usually we have to deploy Deployment, Service, ConfigMap and so on, depends on application design which is hard to do manually. Helm helps to simplify those step by provide template and ability to inject variable(value) to template.Terminology Chart : It is packaging format. Including a set of k8s definition depends on application and Chart definition file.Chart file structure (only important)helm/ Chart.yaml # Contain metadata of Chart. Eg. Chart name, version values.yaml # default configuration templates/ # K8s manifest deployment.yaml service.yaml ingress.yaml ...Helm dependenciesIn case that we want to add another Helm application as dependency, we can add its information in Chart.yaml. For example, Create own ELK Chart that consist of Kinaba, ElasticSearch and Logstash by declear them as dependencies. Value can pass down to subchart by add prefix to value.InstallWhen install parameter in template will be replaced by value in values.yamltemplates/ + =&amp;gt; Kubernetes manifest =&amp;gt; Go into K8svalues.yaml" }, { "title": "Dockerfile", "url": "/posts/dockerfile/", "categories": "devops", "tags": "devops, docker", "date": "2021-09-05 14:30:00 +0800", "snippet": "Dockerfile instructionInstruction is information on how to build docker image.FROMFROM image:tag AS aliasFROM node:14 AS build-image FROM initializes a new build stage and base image for subsequent instructions. Images can be pull from - public or private repository. FROM can appear mutiple times to used for make a build stage that can be copy and use on the final stage.WORKDIRWORKDIR partWORKDIR /path/to/workdir This set the working directory inside docker(also create directory). This will affect the rest instruction that refer to directory.COPYCOPY . /appCOPY source_dir destination_dir This copy file from outside of docker into insideADDAPP . /appAPP source_dir destination_dir This is extended from COPY. There is 2 other ways to import to docker that copy way.ENVENV endpoint=http://loaclhost:8080ENV key=value This set environment variable inside docker to be the given value.ARGARG key=default-valueARG pet=cat This defind the variable that user can pass when exeucte “docker build” and we can also defind the default value to be used in case that user omitted the value.RUNRUN apt-get update &amp;amp;&amp;amp; apt-get install gitRUN command (shell form)RUN [“executable”, “param1”, “param2”] (exec form) RUN usually used for install package required for application to run.CMDCMD [“echo”, “Hello World”]CMD [“executable”, “param1”, “param2”] (exec form)CMD echo “Hello World”CMD command param1 param2 (shell form) CMD main purpose is to provides default for an executting container. CMD can be overriden by arguments when execute “docker run”.ENTRYPOINTENTRYPOINT [“echo”, “Hello World”]ENTRYPOINT [“executable”, “param1”, “param2”] (exec form)ENTRYPOINT echo “Hello World”ENTRYPOINT command param1 param2 (shell form) This works similar to CMD but the difference is that command and params aren’t ignored when run container with passing command and params. ENTRYPOINT and CMD can work together as ENTRYPOINT-&amp;gt; should execute anyway command and CMD -&amp;gt; command default args.EXPOSEEXPOSE 8080EXPOSE port This will expose the specified port on container with TCP as default protocal. User can use this port later when run container to forwards request into container." }, { "title": "Docker101", "url": "/posts/docker/", "categories": "devops", "tags": "devops, docker", "date": "2021-09-05 14:00:00 +0800", "snippet": "Docker🐳Docker is the tool for build image(packeage application) from DockerFile and run in a loosely isolated environment called container. Docker isn’t only the tool for making container application but it’s the most famous.Terminology Container : A container is a runnable instance of an image. Image : An image is read-only template with instruction for creating Docker container. It can be compared to class or blueprint. Image is packed in format called Open Container Initiative (OCI).DockerfileDockerfile contains instruction on how to build an image.Docker orchestration tools Docker Swarm : Provider along with Docker Kubernetes(K8s) : Opensource prodject from Google Openshift : Implement on top of K8s by Redhat teamDocker registryDocker registry is used for store Docker images. Docker hub is public registry. There are also private registry that provided by cloud provider.Alternative Podman runc" }, { "title": "Kubernetes network type", "url": "/posts/k8s-network101/", "categories": "devops", "tags": "devops, kubernetes", "date": "2021-09-05 12:00:00 +0800", "snippet": "NetworkFor bare Docker application, We have to expose port to host machine then another application can access it using hostIP:port. This is find but not suit well in cluster environment like K8s because Pod is considered as ephemeral resource which means its IP isn’t consistent.ServiceService is an abstraction layer on top of Pod. It helps application client to access application(Pod) without knowing Its location(IP). For external access, see Ingress. Feature/Type ClusterIP NodePort LoadBalancer Access from Only in cluster using service name Access using any cluster node IP and specific port Access using LB IP How to access serivce-name:port clusterIP:nodePort LoadBalanceIP:Port " }, { "title": "Kubernetes useful commandline", "url": "/posts/k8s-cli/", "categories": "devops", "tags": "devops, kubernetes", "date": "2021-09-05 11:00:00 +0800", "snippet": "KubectlUse for interact with cluster, from read pods specification to create new resources.examplekubectl get [resourceType|CRD] [name]kubectl describe [resourceName|CRD] [name]KubensUse for list and select the current working namespace. It helps to avoid tedious task to put namespace for every K8s cli.KubectxUse for set K8s context, change cluster that currently working with.Tricks kubectl run curl-test –image=radial/busyboxplus:curl -i –tty –rmrun a single pod of busyboxplus for curl or investigation inside cluster" }, { "title": "YAML101", "url": "/posts/yaml/", "categories": "misc", "tags": "", "date": "2021-09-04 23:00:00 +0800", "snippet": "YAML stands for YAML Ain’t Markup Language. It is super set of JSON. Therefore every JSON can convert to YAML but not the way around.Feature#Mapkey : value#Nested mapparent_key : child_key1 : value1 child_key2 : value2#Sequencelist_of_sth: - first_item - second_item - thrid_item#Mutiline stringmutiline_newline : | this is consider and newline and &quot;Newline&quot; character is preservemutiline_folded_string : &amp;gt; this is consider as folded string newline&#39;ll be replaced by space#Document separatordoc1---doc2Tools yamllint : validate yamlhttps://github.com/adrienverge/yamllint" }, { "title": "Kubernetes101", "url": "/posts/k8s/", "categories": "devops", "tags": "devops, kubernetes", "date": "2021-09-04 23:00:00 +0800", "snippet": "Kubernetes☸️Kubernetes or K8s is container orchestration tool. It provides many useful solution of scaling , service discovery, configuration and secret management and so on.Why we need KuberetesFor simple application, we can just docker run or docker-compose to deploy. But for load intensive, high availablity application, Kubernetes gives us tools to achieve that.Terminology Worksloads Node : Machine(vistual or physical) that used for run Pods Pod : Pod is a group of one or more containers. It can be considered as wrapper of Container(s). Normally, we don’t deploy Pod directly but rather create Pod using workload resources such as Deployment, Job or StatefulSet Network Service : This give abstract way to expose application without knowing the Pod being behind. Ingress : Ingress is specification of proxy used for expose Service. It can be used for routing, load balancer, WAF and so on. IngressController : This is actual implementation of Ingress, without this Ingress can’t be used.One of famous IngressController is Nginx. Workload resources Deployment : It’s instruction of desired state of application. We can set how many pod to deploy, deployment strategy and so on. StatefulSet : Similar to Deployment but for stateful applications such as database. DaemonSet : DaemonSet ensures that Nodes(or somes) run a copy of Pod. One of use cases is log collector. Storage PersistentVolumeA(PV) : is a piece of storage in the cluster that provisioned manually or using StorageClass. PV also contain information about specific detail. PersistentVolumeClaima(PVC) : is a request for storage to attached to Pod. Relation between PV and PVC is similar to Pod and Node.Pod consumes Node resources and PVC consumes PV resources. PCV has 2 properties, size and access mode. StorageClass : with PV, user have to create volume statically before use. By StorageClass, volume can be provisioned dynamically. Configuration ConfigMap : ConfigMap is key-value pairs data that can be injected to Pod. Pods can consumes ConfigMaps as env variables, cmd arguments or configuration files. Secret : Similar to ConfigMap but for sensitive data. Eg. TLS secrets, database password. Access control Service accounts : User that respresents Pod to when interact wih apiserver in K8s. Roles : A set of permissions with a particular namespace. Permission is defined by resources type(target of action) and verbs(action) ClusterRole : Similar to Roles but not restrict to a namespace. It define roles on cluster scope Eg. Nodes. RoleBindings : Grant a role to users, service accounts. ClusterRoleBindings : Similar to RoleBindings but for ClusterRole. Custom Resource Definition(CRD) : is extension of the K8s API. CRD can be defind and installed. Eg. ArgoCD Applicatgion, IstioOperator. Kubernetes Objects :K8s can describe in YAML file with 4 required fields. apiVersion : version of K8s api. kind : type of K8s object. Eg. Pod, Serivce. metadata : data helps to identify object labels : key-value pairs that used for describe object. Eg. name, version, managed-by. Labels can be used for select objects(think of tags). annotations : key-value paris used for add some metadata for others(human or K8s object) to get metadata. spec : the desired state of object. details depends on type of K8s object. selector : we can select K8s object using labels. " } ]
